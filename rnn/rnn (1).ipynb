{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jj3TKl1vHvRz"
      },
      "outputs": [],
      "source": [
        "# Imports\n",
        "import os\n",
        "import joblib\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential, load_model\n",
        "from tensorflow.keras.layers import SimpleRNN, Dense, BatchNormalization, Dropout\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "# Function to process data\n",
        "def processData(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    data['closing_return'] = data['close'].pct_change()\n",
        "    data['target'] = (data['closing_return'].shift(-1) > 0).astype(int)  # Ensure target is an integer\n",
        "    data['spread'] = data['high'] - data['low']\n",
        "    data['closing_return'] = data['closing_return'].fillna(0)\n",
        "    return data\n",
        "\n",
        "# Load and Clean Data\n",
        "path = os.path.join('/content/drive/MyDrive/findata/train.csv')\n",
        "data = pd.read_csv(path)\n",
        "data = processData(data)\n",
        "data['closing_return'] = data['closing_return'].fillna(0)\n",
        "\n",
        "# Function to create input data for the neural network\n",
        "def create_nn_data(data, batch_size=10, save_scaler=True):\n",
        "    X = data.drop(columns=['target']).values\n",
        "    y = data['target'].values\n",
        "    y = y[:len(y) - len(y) % batch_size : batch_size]\n",
        "    y = y.reshape(-1, 1, 1)\n",
        "\n",
        "    X = X[:len(X) - len(X) % batch_size]\n",
        "\n",
        "    scaler_path = os.path.join('/content/trained-models/scaler.joblib')\n",
        "    if save_scaler:\n",
        "        os.makedirs(os.path.dirname(scaler_path), exist_ok=True)  # Create directory if it doesn't exist\n",
        "        scaler = MinMaxScaler()\n",
        "        X = scaler.fit_transform(X)\n",
        "        joblib.dump(scaler, scaler_path)\n",
        "    else:\n",
        "        scaler = joblib.load(scaler_path)\n",
        "        X = scaler.transform(X)\n",
        "\n",
        "    X = X.reshape(-1, batch_size, X.shape[1])\n",
        "\n",
        "    return X, y\n",
        "\n",
        "# Create neural network data\n",
        "BATCH_SIZE = 5\n",
        "X, y = create_nn_data(data, batch_size=BATCH_SIZE)\n",
        "\n",
        "# Build the Model\n",
        "model = Sequential()\n",
        "model.add(SimpleRNN(64, return_sequences=True, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))  # Add dropout for regularization\n",
        "\n",
        "model.add(SimpleRNN(64, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))  # Add another dropout layer\n",
        "\n",
        "model.add(SimpleRNN(64, return_sequences=True))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Dropout(0.2))  # Add another dropout layer\n",
        "\n",
        "model.add(SimpleRNN(64))  # Last RNN layer without return_sequences\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer=Adam(learning_rate=0.0001), loss='binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "history = model.fit(X, y, epochs=20, batch_size=BATCH_SIZE)  # Increased epochs\n",
        "\n",
        "\n",
        "# Save the model for later\n",
        "model_path = os.path.join('/content/trained-models/neural-net.keras')\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)  # Create directory if it doesn't exist\n",
        "model.save(model_path)\n",
        "\n",
        "# Evaluate out-of-sample performance\n",
        "test = pd.read_csv(os.path.join('/content/drive/MyDrive/findata/test.csv'))\n",
        "test = processData(test)\n",
        "actual = test['target'].copy()\n",
        "row_id = test['row_id'].copy()\n",
        "test = test.drop(columns=['row_id', 'target'])\n",
        "\n",
        "# Prepare test data for predictions\n",
        "test = test.values\n",
        "scaler = joblib.load(os.path.join('/content/trained-models/scaler.joblib'))\n",
        "test = scaler.transform(test)\n",
        "\n",
        "# Create input sequences for testing\n",
        "X_test = []\n",
        "for i in range(len(test) - BATCH_SIZE):\n",
        "    X_test.append(test[i:i+BATCH_SIZE])\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Load the model and make predictions\n",
        "model = load_model(model_path)\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.pad(y_pred.flatten(), (0, BATCH_SIZE), mode='constant', constant_values=0)\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission = pd.DataFrame({'row_id': row_id, 'target': y_pred.flatten()})\n",
        "submission['target'] = submission['target'].apply(lambda x: 1 if x > 0.5 else 0)\n",
        "\n",
        "# Save submission to CSV\n",
        "submission.to_csv(os.path.join('submission.csv'), index=False)  # Adjusted path for Colab\n",
        "\n",
        "# Compare to the real target\n",
        "submission['actual'] = actual.astype(int)\n",
        "submission['correct'] = (submission['target'] == submission['actual']).astype(int)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Save the model for later\n",
        "model_path = os.path.join('/content/trained-models/neural-net.keras')\n",
        "os.makedirs(os.path.dirname(model_path), exist_ok=True)  # Create directory if it doesn't exist\n",
        "model.save(model_path)\n",
        "\n",
        "# Evaluate out-of-sample performance\n",
        "test = pd.read_csv(os.path.join('/content/drive/MyDrive/findata/test.csv'))\n",
        "test = processData(test)\n",
        "actual = test['target'].copy()\n",
        "row_id = test['row_id'].copy()\n",
        "test = test.drop(columns=['row_id', 'target'])\n",
        "\n",
        "# Prepare test data for predictions\n",
        "test = test.values\n",
        "scaler = joblib.load(os.path.join('/content/trained-models/scaler.joblib'))\n",
        "test = scaler.transform(test)\n",
        "\n",
        "# Create input sequences for testing\n",
        "X_test = []\n",
        "for i in range(len(test) - BATCH_SIZE):\n",
        "    X_test.append(test[i:i+BATCH_SIZE])\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Load the model and make predictions\n",
        "model = load_model(model_path)\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred = np.pad(y_pred.flatten(), (0, BATCH_SIZE), mode='constant', constant_values=0)\n",
        "\n",
        "# Prepare submission DataFrame\n",
        "submission = pd.DataFrame({'row_id': row_id, 'target': y_pred.flatten()})\n",
        "submission['target'] = submission['target'].apply(lambda x: 1 if x > 0.5 else 0)\n",
        "\n",
        "# Save submission to CSV\n",
        "submission.to_csv(os.path.join('submission.csv'), index=False)\n",
        "\n"
      ],
      "metadata": {
        "id": "9C_yf1kVH6f4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "O0yoKRp0vIIq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}